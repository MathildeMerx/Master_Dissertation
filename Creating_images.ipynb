{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Creating-a-table-of-all-the-values\" data-toc-modified-id=\"Creating-a-table-of-all-the-values-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Creating a table of all the values</a></span><ul class=\"toc-item\"><li><span><a href=\"#For-2010-to-2014\" data-toc-modified-id=\"For-2010-to-2014-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>For 2010 to 2014</a></span></li><li><span><a href=\"#For-2015-to-2019\" data-toc-modified-id=\"For-2015-to-2019-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>For 2015 to 2019</a></span></li><li><span><a href=\"#S&amp;P-index\" data-toc-modified-id=\"S&amp;P-index-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>S&amp;P index</a></span></li></ul></li><li><span><a href=\"#Three-types-of-images\" data-toc-modified-id=\"Three-types-of-images-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Three types of images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recurrence-plot\" data-toc-modified-id=\"Recurrence-plot-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Recurrence plot</a></span></li><li><span><a href=\"#Gramian-Angular-Field\" data-toc-modified-id=\"Gramian-Angular-Field-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Gramian Angular Field</a></span></li><li><span><a href=\"#Markov-Transition-Field\" data-toc-modified-id=\"Markov-Transition-Field-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Markov Transition Field</a></span></li></ul></li><li><span><a href=\"#3-channels\" data-toc-modified-id=\"3-channels-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>3-channels</a></span></li><li><span><a href=\"#Dataset-other-label\" data-toc-modified-id=\"Dataset-other-label-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Dataset other label</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Testing</a></span></li><li><span><a href=\"#S&amp;P-index\" data-toc-modified-id=\"S&amp;P-index-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>S&amp;P index</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the images from the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, to_datetime, Timestamp\n",
    "from os import listdir, remove\n",
    "from os.path import isfile, join\n",
    "from math import log, cos, acos\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pywt\n",
    "from matplotlib.image import imsave\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from re import split\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a table of all the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 2010 to 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove('training/AMCR.csv')\n",
    "# remove('training/TT.csv')\n",
    "# remove('training/CFG.csv')\n",
    "# remove('training/INFO.csv')\n",
    "# remove('training/ANET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_companies_name = [f[:-4] for f in listdir('training') if isfile(join('training', f))]\n",
    "train_companies_name = [train_companies_name[i] if i%15 < 8 else None for i in range(len(train_companies_name))]\n",
    "train_num_companies = len(train_companies_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv('training/' + train_companies_name[0] + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stocks_data = [0 for x in range(train_num_companies)]\n",
    "\n",
    "for i in range(train_num_companies):\n",
    "    if train_companies_name[i] != None:\n",
    "    \n",
    "        data = read_csv('training/' + train_companies_name[i] + '.csv')\n",
    "\n",
    "        opening = [log(x) for x in (data['Open'].values[1:]/data['Open'].values[:-1])][1:]\n",
    "\n",
    "        close = [log(x) for x in (data['Close'].values[1:]/data['Close'].values[:-1])][:-1]\n",
    "\n",
    "        high = [log(x) for x in (data['High'].values[1:]/data['High'].values[:-1])][:-1]\n",
    "\n",
    "        low = [log(x) for x in (data['Low'].values[1:]/data['Low'].values[:-1])][:-1]\n",
    "\n",
    "        label = [1 if x == True else 0 for x in data['Close'].values > data['Open'].values][2:]\n",
    "\n",
    "        train_stocks_data[i] = np.array([opening, close, high, low, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 2015 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove('testing/AMCR.csv')\n",
    "# remove('testing/TT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_companies_name = [f[:-4] for f in listdir('testing') if isfile(join('testing', f))]\n",
    "test_companies_name = [test_companies_name[i] for i in range(0, len(test_companies_name), 5)]\n",
    "\n",
    "test_num_companies = len(test_companies_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_stocks_data = []\n",
    "names = []\n",
    "\n",
    "for i in range(test_num_companies):\n",
    "    data = read_csv('testing/' + test_companies_name[i] + '.csv')\n",
    "    \n",
    "    if len(data) == 1258:        \n",
    "        opening = np.array([log(x) for x in (data['Open'].values[1:]/data['Open'].values[:-1])][1:-1])\n",
    "        \n",
    "        close = np.array([log(x) for x in (data['Close'].values[1:]/data['Close'].values[:-1])][:-2])\n",
    "        \n",
    "        high = np.array([log(x) for x in (data['High'].values[1:]/data['High'].values[:-1])][:-2])\n",
    "        \n",
    "        low = np.array([log(x) for x in (data['Low'].values[1:]/data['Low'].values[:-1])][:-2])\n",
    "        \n",
    "        date = np.array(to_datetime(data['Date']).sub(Timestamp('2015-01-01')).dt.days.values[2:-1])\n",
    "        \n",
    "        label = np.array([1 if x == True else 0 for x in (data['Close'].values > data['Open'])][2:-1])\n",
    "        \n",
    "        test_stocks_data.append(np.array([opening, close, high, low, date, label]))\n",
    "        \n",
    "        names.append(test_companies_name[i])\n",
    "\n",
    "test_stocks_data = np.array(test_stocks_data)\n",
    "\n",
    "test_companies_name = names\n",
    "\n",
    "test_num_companies = len(test_companies_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('s&p.csv')\n",
    "\n",
    "opening = [log(x) for x in (data['Open'].values[1:]/data['Open'].values[:-1])][1:]\n",
    "\n",
    "close = [log(x) for x in (data['Close'].values[1:]/data['Close'].values[:-1])][:-1]\n",
    "\n",
    "high = [log(x) for x in (data['High'].values[1:]/data['High'].values[:-1])][:-1]\n",
    "\n",
    "low = [log(x) for x in (data['Low'].values[1:]/data['Low'].values[:-1])][:-1]\n",
    "\n",
    "close_values = data['Close'].values[2:]\n",
    "\n",
    "open_values = data['Open'].values[2:]\n",
    "\n",
    "date = to_datetime(data['Date']).sub(Timestamp('2015-01-01')).dt.days.values[2:]\n",
    "\n",
    "sandp = np.array([opening, close, high, low, close_values, open_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three types of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rp(table, show = False):\n",
    "    n = len(table)\n",
    "    \n",
    "    #First, we rescale (a copy of) our table from 0 to 1\n",
    "    maxi = max(table)\n",
    "    mini = min(table)\n",
    "    \n",
    "    #If all the elements of the table are equal, we only want a black image \n",
    "    if (maxi == mini):\n",
    "        img = 255 * np.ones((n,n))\n",
    "        \n",
    "    else: \n",
    "        copy_table = table.copy()\n",
    "        for i in range(n):\n",
    "            copy_table[i] = (copy_table[i] - mini)/ (maxi - mini)\n",
    "\n",
    "        #Now, we create our recurrence plot image\n",
    "        img = np.zeros((n,n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                img[i][j] = 1 - (1 if (abs(copy_table[i] - copy_table[j]) < 0.1) else (abs(copy_table[i] - copy_table[j])))\n",
    "\n",
    "        #We need to rescale our values from 0 to 255, to obtain a greyscale\n",
    "        mini = np.amin(img)\n",
    "        maxi = np.amax(img)\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                img[i][j] = int((img[i][j] - mini)/ (maxi - mini) * 255)\n",
    "    \n",
    "    if show: \n",
    "        imshow(img, cmap = 'gray')\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(rp(train_stocks_data[0][0][240:256]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gramian Angular Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaf(table, show = False):\n",
    "    n = len(table)\n",
    "    \n",
    "    #First, we rescale (a copy of) our table from -1 to 1\n",
    "    maxi = max(table)\n",
    "    mini = min(table)\n",
    "    \n",
    "    #If all the elements of the table are equal, we only want a black image \n",
    "    if (maxi == mini):\n",
    "        img = 255 * np.ones((n,n))\n",
    "        \n",
    "    else: \n",
    "        copy_table = table.copy()\n",
    "        for i in range(n):\n",
    "            copy_table[i] = (copy_table[i] - mini)/ (maxi - mini)\n",
    "            if abs(copy_table[i]) > 1:\n",
    "                copy_table[i] = np.sign(copy_table[i])\n",
    "            copy_table[i] = acos(copy_table[i])\n",
    "\n",
    "        #Now, we create our recurrence plot image\n",
    "        img = np.zeros((n,n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                img[i][j] = cos(copy_table[i] + copy_table[j])\n",
    "\n",
    "        #We need to rescale our values from 0 to 255, to obtain a greyscale\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                img[i][j] = int((img[i][j] + 1) * 127.5)\n",
    "    \n",
    "    if show: \n",
    "        imshow(img, cmap = 'grey')\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(gaf(train_stocks_data[0][0][240:256]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Transition Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile(arr, nb):\n",
    "    thresh = [np.quantile(arr, (i + 1.0) / nb) for i in range(nb)]\n",
    "    res = np.zeros(len(arr))\n",
    "    for i in range(len(arr)):\n",
    "        quantile = 0\n",
    "        while arr[i] > thresh[quantile]:\n",
    "            quantile += 1\n",
    "        res[i] = quantile\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtf(arr, show = False, nb = Q):\n",
    "    \n",
    "    quant = quantile(arr, nb)\n",
    "    img = np.zeros((nb,nb))\n",
    "    \n",
    "    for i in range(len(quant) - 1):\n",
    "        abscissa = int(quant[i])\n",
    "        ordinate = int(quant[i + 1])\n",
    "        img[abscissa, ordinate] += 1\n",
    "    \n",
    "    for i in range(nb):\n",
    "        if sum(img[:,i]) != 0:\n",
    "            img[:,i] /= sum(img[:,i])\n",
    "        \n",
    "    img = (-img + 1) * 255\n",
    "    \n",
    "    if show: \n",
    "        imshow(img, cmap = 'grey')\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(mtf(train_stocks_data[0][0][:256]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_channels(table_open, table_close, table_high, table_low, table_open_mtf, table_close_mtf, table_high_mtf, table_low_mtf, show = False):\n",
    "    \n",
    "    ### THIS IS THE MTF PART OF THE IMAGE ###\n",
    "    \n",
    "    mtf_open = mtf(table_open_mtf)\n",
    "    mtf_close = mtf(table_close_mtf)\n",
    "    mtf_high = mtf(table_high_mtf)\n",
    "    mtf_low = mtf(table_low_mtf)\n",
    "    \n",
    "    mtf_img = np.concatenate((np.concatenate((mtf_open,mtf_high), axis = 1), \n",
    "                            np.concatenate((mtf_low,mtf_close), axis = 1)), \n",
    "                            axis = 0)\n",
    "    \n",
    "        \n",
    "    ### THIS IS THE GAF PART OF THE IMAGE ###\n",
    "    \n",
    "    gaf_open = gaf(table_open)\n",
    "    gaf_close = gaf(table_close)\n",
    "    gaf_high = gaf(table_high)\n",
    "    gaf_low = gaf(table_low)\n",
    "    \n",
    "    gaf_img = np.concatenate((np.concatenate((gaf_open,gaf_high), axis = 1), \n",
    "                            np.concatenate((gaf_low,gaf_close), axis = 1)), \n",
    "                            axis = 0)\n",
    "    \n",
    "    \n",
    "    ### THIS IS THE RP PART OF THE IMAGE ###\n",
    "    \n",
    "    rp_open = rp(table_open)\n",
    "    rp_close = rp(table_close)\n",
    "    rp_high = rp(table_high)\n",
    "    rp_low = rp(table_low)\n",
    "    \n",
    "    for x in [rp_open, rp_close, rp_high, rp_low]:\n",
    "        LL, (LH, HL, HH) = pywt.dwt2(x, 'bior1.3')\n",
    "        x = np.concatenate((np.concatenate((LL,LH), axis = 1), \n",
    "                            np.concatenate((HL,HH), axis = 1)), \n",
    "                            axis = 0)\n",
    "    \n",
    "        #We need to rescale our values from 0 to 255, to obtain a greyscale\n",
    "        mini = np.amin(x)\n",
    "        maxi = np.amax(x)\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                x[i][j] = int((x[i][j] - mini)/ (maxi - mini) * 255)\n",
    "    \n",
    "    wt_img = np.concatenate((np.concatenate((rp_open,rp_high), axis = 1), \n",
    "                            np.concatenate((rp_low,rp_close), axis = 1)), \n",
    "                            axis = 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### THIS IS THE CONCATENATE OF THE IMAGE ###\n",
    "\n",
    "    img = np.dstack((np.array(gaf_img, dtype='uint8'), np.array(wt_img, dtype='uint8'), np.array(mtf_img, dtype='uint8')))\n",
    "    \n",
    "    if show:\n",
    "        imshow(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(three_channels(train_stocks_data[3][0][240:256], \n",
    "               train_stocks_data[3][1][240:256], \n",
    "               train_stocks_data[3][2][240:256], \n",
    "               train_stocks_data[3][3][240:256],\n",
    "               train_stocks_data[3][0][:256], \n",
    "               train_stocks_data[3][1][:256], \n",
    "               train_stocks_data[3][2][:256], \n",
    "               train_stocks_data[3][3][:256]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset other label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0\n",
    "for i in range(train_num_companies):\n",
    "    for j in range(len(train_stocks_data[i][0]) - 256):\n",
    "        train_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_images = [0 for i in range(train_size)]\n",
    "train_labels = [0 for i in range(train_size)]\n",
    "compt = 0\n",
    "\n",
    "for i in range(train_num_companies):\n",
    "    if i%10==0:\n",
    "        print(str(i) + ' / ' + str(train_num_companies))\n",
    "    for j in range(240, len(train_stocks_data[i][0]) - 16):\n",
    "        train_images[compt] = three_channels(train_stocks_data[i][0][j : j + 16],\n",
    "                                             train_stocks_data[i][1][j : j + 16], \n",
    "                                             train_stocks_data[i][2][j : j + 16],\n",
    "                                             train_stocks_data[i][3][j : j + 16],\n",
    "                                             train_stocks_data[i][0][j - 240 : j + 16],\n",
    "                                             train_stocks_data[i][1][j - 240 : j + 16], \n",
    "                                             train_stocks_data[i][2][j - 240 : j + 16],\n",
    "                                             train_stocks_data[i][3][j - 240 : j + 16])\n",
    "        \n",
    "        train_labels[compt] = (1 if (train_stocks_data[i][0][j + 15] < train_stocks_data[i][1][j + 16]) else 0)\n",
    "        \n",
    "        compt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[218514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('objs_train_label.pkl', 'wb') as f: \n",
    "    pickle.dump([train_images[:218515], train_labels[:218515]], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_days = len(test_stocks_data[0][0]) - 15\n",
    "\n",
    "for j in range(240, test_days):\n",
    "    if j%10 == 0:\n",
    "        print(str(j) + '/' + str(test_days))\n",
    "        \n",
    "    images = [0 for i in range(test_num_companies)]\n",
    "    labels = [0 for i in range(test_num_companies)]\n",
    "    \n",
    "    for i in range(test_num_companies):\n",
    "            images[i] = three_channels(test_stocks_data[i][0][j : j + 16],\n",
    "                                       test_stocks_data[i][1][j : j + 16], \n",
    "                                       test_stocks_data[i][2][j : j + 16],\n",
    "                                       test_stocks_data[i][3][j : j + 16],\n",
    "                                       test_stocks_data[i][0][j - 240 : j + 16],\n",
    "                                       test_stocks_data[i][1][j - 240 : j + 16], \n",
    "                                       test_stocks_data[i][2][j - 240 : j + 16],\n",
    "                                       test_stocks_data[i][3][j - 240 : j + 16])\n",
    "\n",
    "            labels[i] = (1 if (test_stocks_data[i][0][j + 15] < test_stocks_data[i][1][j + 16]) else 0)\n",
    "\n",
    "    with open('testing_label/objs_' + str(j) + '.pkl', 'wb') as f: \n",
    "        pickle.dump([images, labels], f, protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples = len(sandp[0]) - 15\n",
    "\n",
    "sp_images = [0 for i in range(num_samples)]\n",
    "sp_values = [0 for i in range(num_samples)]\n",
    "\n",
    "for i in range(240, num_samples):\n",
    "    if i%10==0:\n",
    "        print(str(i) + '/' + str(num_samples))\n",
    "    sp_images[i] = three_channels(sandp[0][i : i + 16],\n",
    "                                  sandp[1][i : i + 16], \n",
    "                                  sandp[2][i : i + 16],\n",
    "                                  sandp[3][i : i + 16],\n",
    "                                  sandp[0][i - 240 : i + 16],\n",
    "                                  sandp[1][i - 240 : i + 16], \n",
    "                                  sandp[2][i - 240 : i + 16],\n",
    "                                  sandp[3][i - 240 : i + 16])\n",
    "\n",
    "    sp_values[i] = sandp[4][i + 15] / sandp[5][i + 15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('objs_sandp_label.pkl', 'wb') as f: \n",
    "    pickle.dump([sp_images[240:], sp_values[240:]], f, protocol=-1)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
